{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMS4995 HW1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "c2S_wf_djoMA"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/zhichengMLE/deep_learning/blob/master/COMS4995_HW1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "kBQXBvDiUkt4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "509a1243-20ef-4407-e042-8958117a2f2d"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.3.0.post4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "s8nEiZq-Gf06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch, torchvision\n",
        "import torch.optim as optim\n",
        "from numpy import float32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7KQxHltGIOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iwbCLyPe87OH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8934961c-a2a7-42d0-9aa8-bfeeac2d46af"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "#testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FvhqX2vDkFpC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 1"
      ]
    },
    {
      "metadata": {
        "id": "e0Rm0BNcXCW6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_size = len(trainset)\n",
        "train_ratio = 0.9\n",
        "image_flatten_size = trainset[0][0].numpy().size\n",
        "train_size = int(train_ratio * dataset_size)\n",
        "valid_size = dataset_size - train_size\n",
        "\n",
        "\n",
        "train_matrix = np.zeros((image_flatten_size,train_size), dtype = float32)\n",
        "valid_matrix = np.zeros((image_flatten_size,valid_size), dtype = float32)\n",
        "train_label  = np.zeros((train_size, len(classes)),dtype = float32)\n",
        "valid_label  = np.zeros((valid_size, len(classes)),dtype = float32)\n",
        "\n",
        "for i in range(train_size):\n",
        "  temp = trainset[i][0].numpy().flatten()\n",
        "  train_matrix[:,i] = temp\n",
        "  train_label[i][trainset[i][1]] = 1 \n",
        "for i in range(valid_size):\n",
        "  temp = trainset[i+train_size][0].numpy().flatten()\n",
        "  valid_matrix[:,i] = temp\n",
        "  valid_label[i][trainset[i+train_size][1]] = 1 \n",
        "  \n",
        "  \n",
        "train_matrix = train_matrix.T\n",
        "valid_matrix = valid_matrix.T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZeB8TeqRF7Es",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "50db32fb-4d1d-42a0-8e56-8b70a1fb115d"
      },
      "cell_type": "code",
      "source": [
        "print(train_label[9])\n",
        "print(valid_label[9])"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_QJ4ltsl0jwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fa4a9d35-4883-4047-c1f3-4cd6ee0a2008"
      },
      "cell_type": "code",
      "source": [
        "print(np.amax(train_label))\n",
        "print(np.amin(train_label))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nCrEQWvwGi65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, layer_dimensions):\n",
        "        self.layer_dimensions = layer_dimensions\n",
        "        self.parameters = {}\n",
        "        for i in range(1, len(layer_dimensions)):\n",
        "            self.parameters['W' + str(i)] = np.random.randn(layer_dimensions[i], layer_dimensions[i-1])\n",
        "            self.parameters['b' + str(i)] = np.zeros((layer_dimensions[i], 1))\n",
        "            \n",
        "    def affineForward(self, A, W, b):\n",
        "        Z = np.dot(W, A) + b\n",
        "        return Z, (A, W, b)\n",
        "        \n",
        "    def activationForward(self, A, act_func='relu'):\n",
        "        if(act_func == 'sigmoid'):\n",
        "            return self.sigmoid(A)\n",
        "        elif(act_func == 'tanh'):\n",
        "            return self.tanh(A)\n",
        "        elif(act_func == 'relu'):\n",
        "            return self.relu(A)\n",
        "            \n",
        "    def forwardPropagation(self, X):\n",
        "        A = X\n",
        "        cache = []\n",
        "        \n",
        "        for i in range(1, len(self.layer_dimensions)):\n",
        "            A_prev = A\n",
        "            W = self.parameters['W' + str(i)]\n",
        "            b = self.parameters['b' + str(i)]\n",
        "            Z, af_cache = self.affineForward(A_prev, W, b)\n",
        "            A = self.activationForward(Z, act_func='relu')\n",
        "            \n",
        "            \n",
        "            cache.append(af_cache)\n",
        "        return A, cache\n",
        "    \n",
        "    def costFunction(self, AL, y):\n",
        "        print(\"ALShape\",AL.shape,\"Y Shape\",y.shape)\n",
        "        #cost = np.squeeze((-1 / AL.shape[1]) * (np.sum(np.log(AL) * y + np.log(1-AL) * (1-y))))\n",
        "        cost = np.sum(np.log(AL).dot(y) + np.log(1-AL).dot(1-y))\n",
        "        cost = np.squeeze((-1 / AL.shape[1]) * cost)\n",
        "        \n",
        "        #print('Cost: ', cost)\n",
        "        \n",
        "        dAL = -(np.divide(y, AL) - np.divide(1-y, 1-AL))\n",
        "        \n",
        "        return cost, dAL\n",
        "        \n",
        "    def affineBackward(self, dA_prev, cache):\n",
        "        A_prev, W, b = cache\n",
        "        \n",
        "        m = A_prev.shape[1]\n",
        "        \n",
        "        dA = np.dot(W.T, dA_prev)\n",
        "        dW = 1 / m * np.dot(dA_prev, A_prev.T)\n",
        "        db = 1 / m * np.sum(dA_prev, axis=1, keepdims=True)\n",
        "        \n",
        "        return dA, dW, db\n",
        "        \n",
        "    def activationBackward(self, dA, cache, act_func='relu'):\n",
        "        if(act_func == 'sigmoid'):\n",
        "            return self.d_sigmoid(dA)\n",
        "        elif(act_func == 'tanh'):\n",
        "            return self.d_tanh(dA)\n",
        "        elif(act_func == 'relu'):\n",
        "            return self.d_relu(dA)\n",
        "    \n",
        "    def backPropagation(self, dAL, Y, cache):\n",
        "        gradients = {}\n",
        "        \n",
        "        #for i in range(len(self.layer_dimensions)-1, 0, -1):\n",
        "        for i in reversed(range(1, len(self.layer_dimensions))):\n",
        "            lay_cache = cache[i-1]\n",
        "            dZ = self.activationBackward(dAL, lay_cache, 'relu')\n",
        "            dAL, dW, db = self.affineBackward(dZ, lay_cache)\n",
        "            \n",
        "            gradients['dW' + str(i)] = dW\n",
        "            gradients['db' + str(i)] = db\n",
        "            \n",
        "        return gradients\n",
        "        \n",
        "    def updateParameters(self, gradients, alpha):\n",
        "        for i in range(1, len(self.layer_dimensions)):\n",
        "            dW = gradients['dW' + str(i)]\n",
        "            db = gradients['db' + str(i)]\n",
        "        \n",
        "        \n",
        "            self.parameters['W' + str(i)] = self.parameters['W' + str(i)] - alpha * dW\n",
        "            self.parameters['b' + str(i)] = self.parameters['b' + str(i)] - alpha * db\n",
        "        \n",
        "    def train(self, X_train, X_val, y_train, y_val, iters, alpha, batch_size):\n",
        "        counter = 0\n",
        "        for i in range(iters):\n",
        "           \n",
        "            iter_cost = 0\n",
        "            for j in range(math.ceil(len(X_train) / batch_size)):\n",
        "                X_batch, y_batch = self.get_batch(X_train, y_train, j * batch_size, batch_size)\n",
        "                y_pred, cache = self.forwardPropagation(X_batch.T)\n",
        "                \n",
        "                cost, dAL = self.costFunction(y_pred, y_batch)\n",
        "                gradients = self.backPropagation(dAL, y_batch, cache)\n",
        "               \n",
        "                self.updateParameters(gradients, alpha)\n",
        "                iter_cost += cost # @TODO might be wrong since average in costFunction\n",
        "                \n",
        "                \n",
        "            y_pred_val = self.predict(X_val.T)\n",
        "            val_cost, _ = self.costFunction(y_pred_val, y_val)\n",
        "            print('%d / %d' %(i+1, iters))\n",
        "            print('train cost : ', iter_cost / math.ceil(len(X_train) / batch_size))\n",
        "            print('validation cost : ', val_cost)\n",
        "            \n",
        "            \n",
        "    def get_batch(self, X, y, start_idx, batch_size):\n",
        "        end_idx = start_idx + batch_size\n",
        "        if(end_idx > len(X) - 1):\n",
        "            end_idx = len(X) - 1\n",
        "        return X[start_idx:end_idx, :], y[start_idx:end_idx, :]\n",
        "        \n",
        "    def predict(self, X_new):\n",
        "        y_pred, cache = self.forwardPropagation(X_new)\n",
        "        return y_pred\n",
        "    \n",
        "    def sigmoid(self, Z):\n",
        "        A = 1 / (1 + np.exp(-Z))\n",
        "        return A\n",
        "   \n",
        "    def tanh(self, Z):\n",
        "        return np.tanh(Z)\n",
        "   \n",
        "    def relu(self, Z):\n",
        "        A = np.maximum(0, Z)\n",
        "        return A\n",
        "    \n",
        "    def d_sigmoid(self, Z):\n",
        "        return Z * (1.0 - Z)\n",
        "\n",
        "    def d_tanh(self, Z):\n",
        "        return 1.0 - np.tanh(Z) ** 2\n",
        "    \n",
        "    def d_relu(self, Z):\n",
        "        Z[Z >= 0] = 1\n",
        "        Z[Z < 0 ] = 0\n",
        "        return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQC9xpyxKIUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "2c782917-d582-4267-8e1d-64cab9ddd904"
      },
      "cell_type": "code",
      "source": [
        "layer_dimensions = [train_matrix.shape[1], 5, 10]\n",
        "dnn = NeuralNetwork(layer_dimensions)\n",
        "dnn.train(train_matrix, valid_matrix, train_label, valid_label, iters=10, alpha=0.01, batch_size=1000)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ALShape (10, 1000) Y Shape (1000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-54e267c6d9a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlayer_dimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-146-593138b0a259>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, X_val, y_train, y_val, iters, alpha, batch_size)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdAL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcostFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-146-593138b0a259>\u001b[0m in \u001b[0;36mcostFunction\u001b[0;34m(self, AL, y)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#print('Cost: ', cost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mdAL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1000,10) (10,1000) "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xDQdtrmWUlNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cfa0d914-9931-4be5-fd48-b1e663049129"
      },
      "cell_type": "code",
      "source": [
        "testset"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 10000\n",
              "    Split: test\n",
              "    Root Location: ./data\n",
              "    Transforms (if any): Compose(\n",
              "                             ToTensor()\n",
              "                             Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "                         )\n",
              "    Target Transforms (if any): None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "1aKQBer2Uveu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "be3cb95d-87ed-4e9a-892b-d8ecda43ff77"
      },
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "imshow(testset[5][0]) # displays test image number 5\n",
        "print(testset[5][1]) # displays test image number 5\n",
        "print(dnn.predict(testset[5][0]))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-1c53fbe805fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# displays test image number 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# displays test image number 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dnn' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f29e4ff36d8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SPc7ogqiHCoa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "htcLt3M7jldD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c2S_wf_djoMA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 2"
      ]
    },
    {
      "metadata": {
        "id": "lxg9aVx2juPi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hwg3O7pZlktO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j69Ok2V0ly0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "outputId": "b925e90d-c0c6-4e5a-cb4b-2959738be638"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-fe85c778b0e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0408d9e1a14c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument 0 is not a Variable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "I4C0UuwkmAbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}